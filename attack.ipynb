{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM38wJmM+VcMVTEi8lZC9FU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ironman20121/Colabfiles/blob/main/attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Q3**\n",
        "### Apply the **TextAttack framework** to assess the vulnerability of **bert-base-uncased-sst2** using the following recipes: 'bert-attack', 'deepwordbug','textbugger', and '*textfooler*'.  Execute each of the above recipes on the ' **bert-base-uncased-sst2**' ' model and and document the outcomes of the attacks. Identify the recipe on which the **'bert-base-uncased-sst2** ' model is most vulnerable. Hint (textattack attack --recipe ?-- **bert-base-uncased-sst2** --num-examples 5)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7vV527t1mzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q textattack"
      ],
      "metadata": {
        "id": "c1yxflz62Z8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **BertAttack**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rLeZ9rz57PjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_LKyIfZ1lD0",
        "outputId": "d2e5e1bc-f274-4394-b13c-0abced1655f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34;1mtextattack\u001b[0m: Updating TextAttack package dependencies.\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "2024-03-31 18:55:19.920868: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-31 18:55:19.921015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-31 18:55:20.020102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-31 18:55:23.614497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 50.2MB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 4.64MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 341kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 703kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 739664.16 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 371765.92 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 528021.26 examples/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "config.json: 100% 477/477 [00:00<00:00, 2.13MB/s]\n",
            "pytorch_model.bin: 100% 438M/438M [00:05<00:00, 82.3MB/s]\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 237kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.74MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 530kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 2.60MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:02<00:00, 154MB/s] \n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 141kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.76MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 3.58MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  unk\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapMaskedLM(\n",
            "    (method):  bert-attack\n",
            "    (masked_lm_name):  BertForMaskedLM\n",
            "    (max_length):  512\n",
            "    (max_candidates):  48\n",
            "    (min_confidence):  0.0005\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.4\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): UniversalSentenceEncoder(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.2\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): RepeatModification\n",
            "    (3): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]2024-03-31 18:56:23.287688: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2024-03-31 18:56:23.322050: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2024-03-31 18:56:23.355970: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2024-03-31 18:56:23.391254: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2024-03-31 18:56:23.430766: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            " 20% 1/5 [03:48<15:14, 228.56s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (97%)\u001b[0m\n",
            "\n",
            "it 's a \u001b[92mcharming\u001b[0m and often \u001b[92maffecting\u001b[0m journey . \n",
            "\n",
            "it 's a \u001b[91mdangerous\u001b[0m and often \u001b[91munpleasant\u001b[0m journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  40% 2/5 [05:39<08:29, 169.74s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (89%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92mdark\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  60% 3/5 [10:21<06:54, 207.07s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "allows us to hope that nolan is \u001b[92mpoised\u001b[0m to embark a major career as a commercial yet \u001b[92minventive\u001b[0m filmmaker . \n",
            "\n",
            "allows us to hope that nolan is \u001b[91maspirations\u001b[0m to embark a major career as a commercial yet \u001b[91minventoriented\u001b[0m filmmaker . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  80% 4/5 [13:14<03:18, 198.69s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91matoufitting\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4: 100% 5/5 [14:59<00:00, 179.82s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (99%)\u001b[0m\n",
            "\n",
            "it 's slow -- very , very \u001b[91mslow\u001b[0m . \n",
            "\n",
            "it 's slow -- very , very \u001b[92msweet\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5: 100% 5/5 [14:59<00:00, 179.84s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 5      |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 16.69% |\n",
            "| Average num. words per input: | 10.6   |\n",
            "| Avg num queries:              | 69.0   |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ],
      "source": [
        "!textattack attack --recipe bert-attack --model bert-base-uncased-sst2 --num-examples 5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 DEEPWORDBUG**"
      ],
      "metadata": {
        "id": "Ay9tKDga7vkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --recipe deepwordbug --model bert-base-uncased-sst2 --num-examples 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2C3Fy2G2d7L",
        "outputId": "e8a24d73-4c70-4243-fc3a-34e14ecf39d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-31 19:15:11.640438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-31 19:15:11.640521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-31 19:15:11.643250: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-31 19:15:14.036249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  unk\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapNeighboringCharacterSwap(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (1): WordSwapRandomCharacterSubstitution(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (2): WordSwapRandomCharacterDeletion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (3): WordSwapRandomCharacterInsertion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): LevenshteinEditDistance(\n",
            "        (max_edit_distance):  30\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            " 20% 1/5 [00:27<01:49, 27.26s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (70%)\u001b[0m\n",
            "\n",
            "it 's a \u001b[92mcharming\u001b[0m and often \u001b[92maffecting\u001b[0m journey . \n",
            "\n",
            "it 's a \u001b[91mchcrming\u001b[0m and often \u001b[91maffectnig\u001b[0m journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  40% 2/5 [01:01<01:32, 30.79s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "unflinchingly bleak and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  60% 3/5 [01:58<01:18, 39.37s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
            "\n",
            "allows \u001b[92mus\u001b[0m to hope that nolan is \u001b[92mpoised\u001b[0m to embark a major career as a commercial yet \u001b[92minventive\u001b[0m \u001b[92mfilmmaker\u001b[0m . \n",
            "\n",
            "allows \u001b[91ms\u001b[0m to hope that nolan is \u001b[91mpodised\u001b[0m to embark a major career as a commercial yet \u001b[91minvenitve\u001b[0m \u001b[91mfdlmmaker\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 0 / 3:  80% 4/5 [02:29<00:37, 37.38s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (97%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91matsounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 1 / 0 / 4: 100% 5/5 [02:50<00:00, 34.01s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's slow -- very , very slow . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 2 / 0 / 5: 100% 5/5 [02:50<00:00, 34.01s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 3      |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 40.0%  |\n",
            "| Attack success rate:          | 60.0%  |\n",
            "| Average perturbed word %:     | 17.43% |\n",
            "| Average num. words per input: | 10.6   |\n",
            "| Avg num queries:              | 16.8   |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3 textbugger**"
      ],
      "metadata": {
        "id": "gk0iL7eb-baV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --recipe textbugger --model bert-base-uncased-sst2 --num-examples 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOQcgWvO72XX",
        "outputId": "6ecab54d-130a-4230-8597-f4a71ad8995f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-31 19:26:56.378770: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-31 19:26:56.378841: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-31 19:26:56.381596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-31 19:26:57.935771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.\n",
            "100% 481M/481M [00:11<00:00, 42.0MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unzipping file /root/.cache/textattack/tmp9em4tn24.zip to /root/.cache/textattack/word_embeddings/paragramcf.\n",
            "\u001b[34;1mtextattack\u001b[0m: Successfully saved word_embeddings/paragramcf to cache.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapRandomCharacterInsertion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (1): WordSwapRandomCharacterDeletion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (2): WordSwapNeighboringCharacterSwap(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (3): WordSwapHomoglyphSwap\n",
            "    (4): WordSwapEmbedding(\n",
            "        (max_candidates):  5\n",
            "        (embedding):  WordEmbedding\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.8\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            " 20% 1/5 [00:49<03:17, 49.41s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's a charming and often affecting journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  40% 2/5 [01:07<01:41, 33.72s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (70%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92msomber\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  60% 3/5 [03:22<02:15, 67.59s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "allows \u001b[92mus\u001b[0m to hope that nolan is poised to embark a major career as a commercial \u001b[92myet\u001b[0m \u001b[92minventive\u001b[0m \u001b[92mfilmmaker\u001b[0m . \n",
            "\n",
            "allows \u001b[91muѕ\u001b[0m to hope that nolan is poised to embark a major career as a commercial \u001b[91mhowever\u001b[0m \u001b[91minvеntive\u001b[0m \u001b[91mcinematographers\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 0 / 3:  80% 4/5 [04:30<01:07, 67.70s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91mastounԁing\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 1 / 0 / 4: 100% 5/5 [04:55<00:00, 59.20s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's slow -- very , very slow . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 2 / 0 / 5: 100% 5/5 [04:55<00:00, 59.20s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 3      |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 40.0%  |\n",
            "| Attack success rate:          | 60.0%  |\n",
            "| Average perturbed word %:     | 17.43% |\n",
            "| Average num. words per input: | 10.6   |\n",
            "| Avg num queries:              | 26.6   |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4 textfooler**"
      ],
      "metadata": {
        "id": "-DRdBpGxAcUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --recipe textfooler --model bert-base-uncased-sst2 --num-examples 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juT9TP5R-gtU",
        "outputId": "5b934a39-d3e9-44e9-ae4f-eeb02df6f626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-31 19:35:02.336175: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-31 19:35:02.336235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-31 19:35:02.337909: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-31 19:35:04.402395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            " 20% 1/5 [02:23<09:32, 143.10s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (100%)\u001b[0m\n",
            "\n",
            "it 's a \u001b[92mcharming\u001b[0m and often \u001b[92maffecting\u001b[0m journey . \n",
            "\n",
            "it 's a \u001b[91mcutie\u001b[0m and often \u001b[91mafflicts\u001b[0m journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  40% 2/5 [03:34<05:21, 107.15s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (96%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92meerie\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  60% 3/5 [09:37<06:25, 192.50s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "allows \u001b[92mus\u001b[0m to hope that nolan is poised to \u001b[92membark\u001b[0m a \u001b[92mmajor\u001b[0m career as a commercial yet \u001b[92minventive\u001b[0m \u001b[92mfilmmaker\u001b[0m . \n",
            "\n",
            "allows \u001b[91mourselves\u001b[0m to hope that nolan is poised to \u001b[91membarked\u001b[0m a \u001b[91msevere\u001b[0m career as a commercial yet \u001b[91mnovelty\u001b[0m \u001b[91msuperintendent\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  80% 4/5 [10:17<02:34, 154.45s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91mbreathless\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4: 100% 5/5 [14:29<00:00, 173.89s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (98%)\u001b[0m\n",
            "\n",
            "it 's slow -- \u001b[91mvery\u001b[0m , \u001b[91mvery\u001b[0m \u001b[91mslow\u001b[0m . \n",
            "\n",
            "it 's slow -- \u001b[92mpretty\u001b[0m , \u001b[92mperfectly\u001b[0m \u001b[92mlent\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5: 100% 5/5 [14:29<00:00, 173.90s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 5      |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 26.51% |\n",
            "| Average num. words per input: | 10.6   |\n",
            "| Avg num queries:              | 77.4   |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key Observations:\n",
        "\n",
        "- BERT-Attack has the highest success rate with 100%, but it also requires the most queries (69.0) on average.\n",
        "- DeepWordBug/TextBugger have a lower success rate of 60%, but they are the most efficient in terms of queries (26.6), modifying a smaller percentage of words on average.\n",
        "- TextFooler also has a 100% success rate, but it modifies the most words (26.51%) and requires a relatively high number of queries (77.4)."
      ],
      "metadata": {
        "id": "HchTqRPBTX62"
      }
    }
  ]
}